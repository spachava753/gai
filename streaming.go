package gai

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"iter"
	"maps"
)

// StreamChunk represents a single chunk of content yielded during streaming generation.
// Each chunk contains a partial Block that will be combined with other chunks
// to form complete blocks in the final response.
//
// The Block field contains partial content that depends on the BlockType:
//   - For "content" blocks: partial text fragments
//   - For "thinking" blocks: partial reasoning fragments
//   - For "tool_call" blocks: either a header (with ID and tool name) or parameter fragments
//
// CandidatesIndex indicates which candidate this chunk belongs to when N>1 is used.
// Currently only CandidatesIndex=0 is supported by the StreamingAdapter.
//
// # Usage Metadata Not Supported
//
// StreamChunk does not include usage metrics (token counts, costs, etc.) for several reasons:
//
//   - OpenAI and Anthropic streaming APIs do not provide per-chunk usage metrics
//   - Gemini streaming can provide chunk-level metrics, but when a single chunk contains
//     multiple tool use blocks, it's impossible to determine how many tokens each individual
//     tool call consumed
//   - Partial metrics during streaming would be misleading since they don't represent
//     the final total usage
//   - Different providers handle usage metrics differently in streaming contexts
//
// Usage metrics are available in the final Response returned by non-streaming generators
type StreamChunk struct {
	Block           Block
	CandidatesIndex int
}

// StreamingGenerator is an interface for generators that support streaming responses.
// It takes a Dialog and optional GenOpts and returns an iterator that yields chunks of content
// as they are generated by the underlying model.
//
// # Usage Metadata in Streaming
//
// StreamingGenerator does not provide usage metrics (token counts, costs, etc.) on individual
// StreamChunk instances for the following reasons:
//
//   - Provider Limitations: OpenAI and Anthropic streaming APIs do not expose per-chunk
//     usage metrics. Only final totals are available at the end of the stream.
//   - Metric Granularity: Gemini can provide some chunk-level metrics, but when multiple
//     tool calls are present in a single chunk, it's impossible to attribute token usage
//     to individual tool calls accurately.
//   - Misleading Partials: Partial usage metrics during streaming would be misleading
//     since they don't represent the complete picture of resource consumption.
//   - Provider Inconsistency: Different providers handle usage reporting differently
//     in streaming contexts, making a unified approach impractical.
//
// To obtain usage metrics, use non-streaming generator methods that provide complete metrics in the Response.
//
// # Streaming Chunk Patterns
//
// Implementations of StreamingGenerator should follow these patterns when yielding chunks:
//
// 1. Content Blocks (Text):
//   - Yield multiple chunks with BlockType="content", ModalityType=Text
//   - Each chunk contains a partial text fragment
//   - Consecutive content chunks will be concatenated during compression
//   - Must set MimeType="text/plain" for text content
//
// 2. Thinking Blocks:
//   - Yield multiple chunks with BlockType="thinking", ModalityType=Text
//   - Each chunk contains a partial reasoning fragment
//   - Consecutive thinking chunks will be concatenated during compression
//   - Must set MimeType="text/plain"
//
// 3. Tool Call Blocks:
//
//   - First chunk: BlockType="tool_call", ID=<unique_id>, Content=<tool_name>
//   - Subsequent chunks: BlockType="tool_call", ID="" (empty), Content=<JSON_fragment>
//   - JSON fragments are concatenated to form complete parameters
//   - The final concatenated JSON must be valid and parse to map[string]any
//
// # Chunk Compression
//
// The StreamingAdapter uses compressStreamingBlocks to convert streaming chunks into
// canonical blocks for the final Response. The compression follows these rules:
//
// - Consecutive blocks of the same type are merged:
//   - Multiple "content" chunks -> Single content block with concatenated text
//   - Multiple "thinking" chunks -> Single thinking block with concatenated text
//
// - Tool calls are reconstructed:
//   - Header chunk (with ID) marks the start of a new tool call
//   - Parameter chunks (no ID) are concatenated to form complete JSON
//   - Final block contains ToolCallInput{Name, Parameters} as JSON
//
// # Constraints and Requirements
//
// 1. Modality Constraints:
//   - Content and Thinking blocks MUST have ModalityType=Text
//   - Tool call blocks MUST have ModalityType=Text
//   - Non-text modalities in streaming are not currently supported
//
// 2. Tool Call Structure:
//   - Tool calls must start with a header chunk (ID set, content = tool name)
//   - Parameter chunks must have empty ID
//   - Parameter chunks when concatenated must form valid JSON
//
// 3. Error Handling:
//   - Yield errors through the iterator's error return value
//   - Once an error is yielded, no further chunks should be yielded
//   - Common errors include rate limits, content policy violations, etc.
//
// 4. Candidate Support:
//   - Currently only CandidatesIndex=0 is supported
//   - Implementations should error if N>1 is requested
//
// # Example Implementation Pattern
//
//	func (g *MyGenerator) Stream(ctx context.Context, dialog Dialog, options *GenOpts) iter.Seq2[StreamChunk, error] {
//	    return func(yield func(StreamChunk, error) bool) {
//	        // Validate inputs
//	        if len(dialog) == 0 {
//	            yield(StreamChunk{}, EmptyDialogErr)
//	            return
//	        }
//
//	        // Start streaming from API
//	        stream := g.api.StartStream(convertDialog(dialog))
//	        defer stream.Close()
//
//	        for event := range stream.Events() {
//	            switch event.Type {
//	            case "text_delta":
//	                if !yield(StreamChunk{
//	                    Block: Block{
//	                        BlockType:    Content,
//	                        ModalityType: Text,
//	                        MimeType:     "text/plain",
//	                        Content:      Str(event.Text),
//	                    },
//	                    CandidatesIndex: 0,
//	                }, nil) {
//	                    return // User stopped iteration
//	                }
//	            case "tool_call_start":
//	                if !yield(StreamChunk{
//	                    Block: Block{
//	                        ID:           event.ToolID,
//	                        BlockType:    ToolCall,
//	                        ModalityType: Text,
//	                        MimeType:     "text/plain",
//	                        Content:      Str(event.ToolName),
//	                    },
//	                    CandidatesIndex: 0,
//	                }, nil) {
//	                    return
//	                }
//	            case "tool_call_delta":
//	                if !yield(StreamChunk{
//	                    Block: Block{
//	                        BlockType:    ToolCall,
//	                        ModalityType: Text,
//	                        MimeType:     "text/plain",
//	                        Content:      Str(event.JSONDelta),
//	                    },
//	                    CandidatesIndex: 0,
//	                }, nil) {
//	                    return
//	                }
//	            case "error":
//	                yield(StreamChunk{}, event.Error)
//	                return
//	            }
//	        }
//	    }
//	}
//
// A Generator implementation may return several types of errors:
//   - [MaxGenerationLimitErr] when the maximum token generation limit is exceeded
//   - [UnsupportedInputModalityErr] when encountering an unsupported input modality
//   - [UnsupportedOutputModalityErr] when requested to generate an unsupported output modality
//   - [InvalidToolChoiceErr] when an invalid tool choice is specified
//   - [InvalidParameterErr] when generation parameters are invalid or out of range
//   - [ContextLengthExceededErr] when input dialog is too long
//   - [ContentPolicyErr] when content violates usage policies
//   - [EmptyDialogErr] when no messages are provided in the dialog
//   - [AuthenticationErr] when there are authentication or authorization issues
type StreamingGenerator interface {
	Stream(ctx context.Context, dialog Dialog, options *GenOpts) iter.Seq2[StreamChunk, error]
}

// StreamingAdapter converts a StreamingGenerator to a Generator by collecting all chunks
// and compressing them into a complete Response. This adapter handles the conversion from
// streaming chunks to the standard Response format expected by the Generator interface.
//
// The adapter:
// 1. Collects all chunks from the StreamingGenerator
// 2. Uses compressStreamingBlocks to merge consecutive chunks of the same type
// 3. Constructs a Response with the compressed blocks
// 4. Sets FinishReason based on whether tool calls are present
//
// Note: This adapter currently only supports single candidate responses (N=1).
// If the streaming generator yields chunks with CandidatesIndex > 0, an error is returned.
type StreamingAdapter struct {
	S StreamingGenerator
}

// compressStreamingBlocks takes a flat list of streaming output blocks and "compresses" them into the canonical output blocks list.
// This function is responsible for merging consecutive chunks of the same type and reconstructing complete blocks
// from the partial chunks yielded during streaming.
//
// Compression rules:
//
//  1. Content blocks: Consecutive "content" blocks with Text modality are concatenated into a single block.
//     Example: ["Hello, ", "world!"] -> ["Hello, world!"]
//
//  2. Thinking blocks: Consecutive "thinking" blocks with Text modality are concatenated into a single block.
//     Example: ["I need to ", "calculate..."] -> ["I need to calculate..."]
//
// 3. Tool call blocks: Tool calls are reconstructed from a header chunk followed by parameter chunks.
//   - Header chunk: Has ID set and Content contains the tool name
//   - Parameter chunks: Have empty ID and Content contains JSON fragments
//   - The parameter chunks are concatenated and parsed as JSON to create a ToolCallInput
//     Example: [{ID:"123", Content:"get_weather"}, {ID:"", Content:'{"city":'}, {ID:"", Content:'"NYC"}'}]
//     -> [{ID:"123", Content:'{"name":"get_weather","parameters":{"city":"NYC"}}'}]
//
// Returns an error if:
//   - A block has an unsupported BlockType
//   - A content/thinking block doesn't have Text modality
//   - Tool call parameter chunks don't form valid JSON
//   - A tool call block is missing its ID in the header chunk
//
// See the unit test in streaming_test.go for expected scenarios.
func compressStreamingBlocks(blocks []Block) ([]Block, error) {
	var (
		result []Block
		i      int
		n      = len(blocks)
	)

	for i < n {
		blk := blocks[i]
		switch blk.BlockType {
		case Thinking:
			// Enforce text modality
			if blk.ModalityType != Text {
				return nil, fmt.Errorf("content block type %q does not have text modality (got %q)", blk.BlockType, blk.ModalityType)
			}
			// Group all consecutive thinking blocks
			j := i + 1
			joined := blk.Content.String()
			extraFields := make(map[string]interface{})
			maps.Copy(extraFields, blk.ExtraFields)
			for j < n && blocks[j].BlockType == Thinking {
				if blocks[j].ModalityType != Text {
					return nil, fmt.Errorf("content block type %q does not have text modality (got %q)", blocks[j].BlockType, blocks[j].ModalityType)
				}
				joined += blocks[j].Content.String()
				maps.Copy(extraFields, blocks[j].ExtraFields)
				j++
			}
			result = append(result, Block{
				BlockType:    Thinking,
				ModalityType: Text, // safe default
				MimeType:     "text/plain",
				Content:      Str(joined),
				ExtraFields:  extraFields,
			})
			i = j
			continue
		case Content:
			// Enforce text modality
			if blk.ModalityType != Text {
				return nil, fmt.Errorf("content block type %q does not have text modality (got %q)", blk.BlockType, blk.ModalityType)
			}
			// Group consecutive content/text blocks
			j := i + 1
			joined := blk.Content.String()
			extraFields := make(map[string]interface{})
			maps.Copy(extraFields, blk.ExtraFields)
			for j < n && blocks[j].BlockType == Content {
				if blocks[j].ModalityType != Text {
					return nil, fmt.Errorf("content block type %q does not have text modality (got %q)", blocks[j].BlockType, blocks[j].ModalityType)
				}
				joined += blocks[j].Content.String()
				maps.Copy(extraFields, blocks[j].ExtraFields)
				j++
			}
			result = append(result, Block{
				BlockType:    Content,
				ModalityType: Text,
				MimeType:     "text/plain",
				Content:      Str(joined),
				ExtraFields:  extraFields,
			})
			i = j
			continue
		case ToolCall:
			// Detect start of new toolcall: block with ID set, content = tool name
			if blk.ID == "" {
				return nil, fmt.Errorf("unexpected: tool_call block with empty ID at start of tool call sequence; full tool call block must have ID (tool name header)")
			}
			id := blk.ID
			toolName := blk.Content.String()
			extraFields := make(map[string]interface{})
			maps.Copy(extraFields, blk.ExtraFields)
			jsonDelta := ""
			j := i + 1
			for j < n && blocks[j].BlockType == ToolCall && blocks[j].ID == "" {
				jsonDelta += blocks[j].Content.String()
				maps.Copy(extraFields, blocks[j].ExtraFields)
				j++
			}
			// Combine all json deltas into one
			var paramMap map[string]any
			if jsonDelta != "" {
				if err := json.Unmarshal([]byte(jsonDelta), &paramMap); err != nil {
					return nil, fmt.Errorf("malformed tool_call param JSON: %w", err)
				}
			} else {
				paramMap = make(map[string]any)
			}
			tci := ToolCallInput{Name: toolName, Parameters: paramMap}
			marshal, err := json.Marshal(tci)
			if err != nil {
				return nil, fmt.Errorf("unable to marshal ToolCallInput: %w", err)
			}
			result = append(result, Block{
				ID:           id,
				BlockType:    ToolCall,
				ModalityType: Text,
				MimeType:     "text/plain",
				Content:      Str(marshal),
				ExtraFields:  extraFields,
			})
			i = j
			continue
		default:
			return nil, fmt.Errorf("unsupported block type %q in streaming generator compression", blk.BlockType)
		}
	}
	return result, nil
}

func (s *StreamingAdapter) Generate(ctx context.Context, dialog Dialog, options *GenOpts) (Response, error) {
	// Stream and accumulate blocks
	var blocks []Block
	for chunk, err := range s.S.Stream(ctx, dialog, options) {
		if err != nil {
			return Response{}, err
		}
		if chunk.CandidatesIndex > 0 {
			return Response{}, errors.New("does not support n > 1 option")
		}
		blocks = append(blocks, chunk.Block)
	}
	comp, err := compressStreamingBlocks(blocks)
	if err != nil {
		return Response{}, err
	}

	finishReason := EndTurn
	for _, blk := range comp {
		if blk.BlockType == ToolCall {
			finishReason = ToolUse
			break
		}
	}

	return Response{
		Candidates: []Message{{
			Role:   Assistant,
			Blocks: comp,
		}},
		FinishReason: finishReason,
	}, nil
}

func (s *StreamingAdapter) Register(tool Tool) error {
	i, ok := s.S.(ToolRegister)
	if !ok {
		return fmt.Errorf("inner generator does not implement ToolRegister")
	}
	return i.Register(tool)
}

func (s *StreamingAdapter) Count(ctx context.Context, dialog Dialog) (uint, error) {
	i, ok := s.S.(TokenCounter)
	if !ok {
		return 0, fmt.Errorf("inner generator does not implement TokenCounter")
	}
	return i.Count(ctx, dialog)
}

var _ ToolCapableGenerator = (*StreamingAdapter)(nil)
